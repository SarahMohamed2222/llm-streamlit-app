# llm-streamlit-app
Interactive Python web app with Streamlit + Ollama, showcasing Llama 3.1 responses.

# ðŸ¦™ LLM Web App with Streamlit & Ollama

This project is a simple Large Language Model (LLM) web application built in Python using:
- **Streamlit** for the UI
- **Ollama** for local model inference
- **Llama 3.1 (8B)** as the model backend

## ðŸš€ Features
- Interactive web-based GUI
- Ask questions and get responses from Llama
- Simple, clean Python code

## ðŸ“¦ Installation
1. Clone the repo:
   ```bash
   git clone https://github.com/SarahMohamed2222/llm-streamlit-app.git
   cd llm-streamlit-app

